expt_dir: experiments
expt_name: mean_flow_mnist
trainer_args:
  max_epochs: 100
  accelerator: "gpu"
  devices: [0,1]
  limit_train_batches: 3200
  limit_val_batches: 1
  check_val_every_n_epoch: 1
  log_every_n_steps: 5
  precision: 32
  strategy: "deepspeed_stage_2"
diffusion_trainer:
  target: pl_trainer.mean_flow_trainer.MeanFlowTrainer
  params:
    accumulate_grad_batches: 8
    loss_weights: 
      l2: 1.0
    optim_args: 
      lr: 5e-5
      weight_decay: 1e-5
    use_8bit_adam: False
    gradient_checkpointing: True
    use_ema: True
    ema_decay: 0.99
    ema_start: 500
    guidance_scale: 2.0
pipe:
  target: pipelines.mean_flow_pipeline.MeanFlowPipeline
  params: {}
denoiser: 
  target: models.mean_flow_model.DualTimestepDiTTransformer2DModel
  params:
    in_channels: 1
    out_channels: 1
    num_layers: 12
    num_attention_heads: 8
    attention_head_dim: 64
data:
  batch_size: 32
  val_batch_size: 8
  train_shuffle: true
  val_shuffle: false
  train:
    target: dataloaders.mnist.MNISTDataset
    params: 
      root: ./
      download: true
      train: true
  val:
    target: dataloaders.mnist.MNISTDataset
    params: 
      root: ./
      download: true
      train: false
callbacks:
  - target: pytorch_lightning.callbacks.ModelCheckpoint
    params:
      dirpath: "${expt_dir}/${expt_name}"
      filename: "{epoch:04d}"
      monitor: epoch
      mode: max
      save_top_k: 2
      save_last: true
  - target: callbacks.training_visualizer.DiffusionTrainingLogger
    params:
      max_num_images: 8
    require_wandb: true
